---
title: "The Data-Intensive Research Workflow"
subtitle: "Orientation Learning Lab Case Study"
author: "YOUR NAME HERE"
date: "`r format(Sys.Date(),'%B %e, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 4
    toc_float: yes
    code_folding: show
    code_download: TRUE
editor_options:
  markdown:
    wrap: 72
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error = FALSE)
```

![](img/LASER_Hx.png){width="40%"}

## INTRODUCTION

Welcome to your first Learning Lab Case Study! The case study activities
included in each learning lab demonstrate how key data-intensive
research workflow processes (i.e., wrangling, visualizing, summarizing,
modeling, and communicating data) featured in exemplary STEM education
research studies are implemented in R. Case studies also provide a
holistic setting to explore important foundational LA topics integral to
data analysis such as reproducible research, use of APIs, and ethical
considerations.

This orientation case study is really just a warm-up activity to
introduce you to R Markdown, which is heavily integrated into each LASER
Learning Labs. You may have used R Markdown before - or you may not
have! Either is fine as this task will be designed with the assumption
that you have not used R Markdown before. In the context of doing so,
we'll focus on the following tasks:

1.  Reading data into R (in the **Prepare** section)
2.  Preparing and "wrangling" data in table (think spreadsheet!) format
    (in the **Wrangle** section)
3.  Creating some basic plots (in the **Explore** section)
4.  Running a model - specifically, a simple regression model (in the
    **Model** section)
5.  Finally, creating a reproducible report of your work you can share
    with others (in the **Communicate** section)

### How to use this R Markdown document

This is an [R Markdown](https://rmarkdown.rstudio.com/) file as
indicated by the .rmd extension at the end of the file name and uses
plain text
[markdown](https://bookdown.org/yihui/rmarkdown/markdown-syntax.html)
syntax. R Markdown documents are fully reproducible and use a productive
[notebook interface](https://bookdown.org/yihui/rmarkdown/notebook.html)
to combine narrative text and "chunks" of code to produce a range of
static or dynamic outputs formats including:
[HTML](https://bookdown.org/yihui/rmarkdown/html-document.html),Â [PDF](https://bookdown.org/yihui/rmarkdown/pdf-document.html),Â [MS
Word](https://bookdown.org/yihui/rmarkdown/word-document.html),Â [HTML5
slides](https://bookdown.org/yihui/rmarkdown/ioslides-presentation.html),Â [Tufte-style
handouts](https://bookdown.org/yihui/rmarkdown/tufte-handouts.html),
[books](#0), [dashboards](#0), [shiny applications](#0),Â [scientific
articles](#0),Â [websites](#0), and more.

There are two keys to your use of R Markdown for this activity:

1.  First, be sure that you are viewing the document in the "Visual
    Editor" mode. You can use this mode by clicking the word "Visual" on
    the left side of the toolbar above. The visual editor allows you to
    see the underlying markdown syntax, or "Source" text, with headers,
    text and code chunks formatted as specified.
2.  Second, note the specially formatted text box below a line of code
    (specified as `{r}` in the upper left corner) and a set of buttons
    in the upper right corner. This is called a "[code
    chunk](https://bookdown.org/yihui/rmarkdown/r-code.html)" and allows
    you to run code directly in your document from [multiple
    languages](https://bookdown.org/yihui/rmarkdown/language-engines.html)including
    R, Python, and SQL.

Click the green arrow button on the right side of the code chunk to run
the R code and view the image file name `laser-cycle.png` stored in the
`img` folder in your files pane.

```{r}
knitr::include_graphics("img/laser-cycle.png")
```

### The Data-Intensive Research Workflow

You may have noticed the words in this diagram correspond to the
sections outlined at the beginning of this documents. What's so special
about preparing, wrangling, exploring, and modeling data - and
communicating results? These terms, or processes, are part of a
framework called the data-intensive research workflow and comes from
Learning Analytics Goes to School [@krumm2018]*.* You can check that
out, but don't feel any need to dive deep for now - we'll be spending
more time on this throughout the week. For now, know that this document
and all of our LASER Lab case studies are organized around these five
components.

Let's get started! We are glad you are here and ready to begin this
exciting (and challenging) journey together.

## 1. PREPARE

First and foremost, data-intensive research involves defining and
refining a research question and developing and understanding of where
your data comes from [@krumm2018]. This part of the process also
involves setting up an environment for reproducible research
[@gandrud2021]. For now, we'll focus on just a few parts of this
process, diving in much more deeply into these components in later
learning labs.

### Packages ðŸ“¦

As highlighted in Chapter 6 of Data Science in Education Using R
[@estrellado2020e], one of the first steps of every workflow should be
to set up your "Project" within RStudio. Recall that:

> A **Project** is the home for all of the files, images, reports, and
> code that are used in any given project

Since we are working from in Posit Cloud with a R project [cloned from
GitHub](https://github.com/laser-institute/laser-orientation), a
"Project" has already been set up for you as indicated by the `.Rproj`
file in your main directory in the Files pane. Go ahead and see if you
can locate it in your project file directory.

With our project already set up for us, we will instead focus on loading
the required packages we'll need for analysis. **Packages**, sometimes
referred to as libraries, are shareable collections of R code that can
contain functions, data, and/or documentation and extend the
functionality of R. You can always check to see which packages have
already been installed and loaded into Posit Cloud by looking at the the
Files, Plots, & Packages Pane in the lower right-hand corner. Click the
packages tab to see which packages have already been installed for this
project.

#### tidyverse ðŸ“¦

![](img/tidyverse.png){width="30%"}

One package that we'll be using extensively is {tidyverse}. The
{tidyverse} package is actually a [collection of R
packages](https://www.tidyverse.org/packages) designed for wrangling and
exploring data (sound familiar?) and which all share an underlying
design philosophy, grammar, and data structures. These shared features
are sometimes "[tidy data
principles](https://r4ds.had.co.nz/tidy-data.html)" [@wickham2016r].

One package that we'll be using a lot is the tidyverse. To load the
tidyverse, click the green arrow in the right corner of the block-or
"chunk"-of code that follows.

```{r}
library(tidyverse)
```

Please do not worry if you saw a number of messages: those probably mean
that the tidyverse loaded just fine. If you see an error, though, try to
interpret or search via your search engine the contents of the error, or
reach out to us for assistance.

### Loading (or reading in) data

Next, we'll load data - specifically, a CSV text file, the kind that you
can export from Microsoft Excel or Google Sheets - into R, using the
`read_csv()` function in the next chunk.

Clicking the green arrow runs the code; do that next to read the
`sci-online-classes.csv` file stored in the `data` folder of your R
project:

```{r}
sci_data <- read_csv("data/sci-online-classes.csv")
```

Nice work! You should now see a new data "object" named `sci_data` saved
in your Environment pane. Try clicking on it and see what happens.

#### Viewing or inspecting data

Now let's learn another way to inspect our data. Run the next chunk and
look at the results, tabbing left or right with the arrows, or scanning
through the rows by clicking the numbers at the bottom of the pane with
the print-out of the data you loaded:

```{r}
sci_data
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

What do you notice about this data set? What do you wonder? Add one-two
thoughts following the dashes next (you can add additional dashes if you
like!):

-   

-   

There are other ways to inspect your data; the `glimpse()` function
provides one such way. Run the code below to take a glimpse at your
data.

```{r}
glimpse(sci_data)
```

We have one more question to pose to you: What do rows and columns
typically represent in your area of work and/or research?

Generally, rows typically represent "cases," the units that we measure,
or the units on which we collect data. This is not a trick question!
What counts as a "case" (and therefore what is represented as a row)
varies by (and within) fields. There may be multiple types or levels of
units studied in your field; listing more than one is fine! Also, please
consider what columns - which usually represent variables - represent in
your area of work and/or research.

#### [**Your Turn**]{style="color: green;"} **â¤µ**

What rows typically (or you think may) represent:

-   

What columns typically (or you think may) represent:

-   

Next, we'll use a few functions that are handy for preparing data in
table form.

## 2. WRANGLE

By wrangle, we refer to the process of cleaning and processing data,
and, in cases, merging (or joining) data from multiple sources. Often,
this part of the process is very (surprisingly) time-intensive.
Wrangling your data into shape can itself be an important
accomplishment! There are great tools in R to do this, especially
through the use of the {dplyr} R package.

### Selecting variables

Let's select only a few variables using a very powerful operator called
a **pipe**. Pipes are a powerful tool for combining a sequence of
functions or processes. The original pipe operator, `%>%`, comes from
the {**magrittr**} package but all packages in the tidyverse loadÂ `%>%`
for you automatically, so you don't usually load magrittr explicitly.

The pipe has become such a useful and much used operator in R that it is
now baked into R using the new and simpler version of the pipe `|>`
operator. Run the following code chunk to `select()` the `student_id`,
`total_points_possible`, and `total_points_earned` variables from our
`sci_data`:

```{r}
sci_data |> 
  select(student_id, total_points_possible, total_points_earned)
```

Notice how the number of columns (variables) is now different.

Let's *include one additional variable* in your select function.

First, we need to figure out what variables exist in our dataset (or be
reminded of this - it's very common in R to be continually checking and
inspecting your data)!

You can use a function named glimpse() to do this.

```{r}
glimpse(d)
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

In the code chunk below, add a new variable to the code below, being
careful to type the new variable name as it appears in the data. We've
added some code to get you started. Consider how the names of the other
variables are separated as you think about how to add an additional
variable to this code.

```{r}
d |> 
  select(student_id, total_points_possible, total_points_earned)
```

Once added, the output should be different than in the code above -
there should now be an additional variable included in the print-out.

### Filtering variables

Next, let's explore filtering variables. Check out and run the next
chunk of code, imagining that we wish to filter our data to view only
the rows associated with students who earned a final grade (as a
percentage) of 70 - 70% - or higher.

```{r}
d |> 
  filter(FinalGradeCEMS > 70)
```

##### [**Your Turn**]{style="color: green;"} **â¤µ**

In the next code chunk, change the cut-off from 70% to some other
value - larger or smaller (maybe much larger or smaller - feel free to
play around with the code a bit!).

```{r}
d |> 
  filter(FinalGradeCEMS > 70)
```

What happens when you change the cut-off from 70 to something else? Add
a thought (or more):

-   

### Arrange

The last function we'll use for preparing tables is arrange.

We'll combine this arrange() function with a function we used already -
select(). We do this so we can view only the student ID and their final
grade.

```{r}
d |> 
  select(student_id, FinalGradeCEMS) |> 
  arrange(FinalGradeCEMS)
```

Note that arrange works by sorting values in ascending order (from
lowest to highest); you can change this by using the desc() function
with arrange, like the following:

```{r}
d |> 
  select(student_id, FinalGradeCEMS) |> 
  arrange(desc(FinalGradeCEMS))
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

In the code chunk below, replace FinalGradeCEMS that is used with both
the select() and arrange() functions with a different variable in the
data set. Consider returning to the code chunk above in which you
glimpsed at the names of all of the variables.

```{r}
d |> 
  select(student_id, FinalGradeCEMS) |> 
  arrange(desc(FinalGradeCEMS))
```

### Reach 1 ðŸŽ‰

Can you compose a series of functions that include the select(),
filter(), and arrange functions? Recall that you can "pipe" the output
from one function to the next as when we used select() and arrange()
together in the code chunk above.

*This reach is not required/necessary to complete; it's just for those
who wish to do a bit more with these functions at this time (we'll do
more in class, too!)*

```{r}

```

## 3. EXPLORE

Exploratory data analysis, or exploring your data, involves processes of
*describing* your data (such as by calculating the means and standard
deviations of numeric variables, or counting the frequency of
categorical variables) and, often, visualizing your data prior. In this
section, we'll create a few plots to explore our data.

### Histogram

The code below creates a histogram, or a distribution of the values, in
this case for students' final grades.

```{r}
ggplot(d, aes(x = FinalGradeCEMS)) +
  geom_histogram()
```

You can change the color of the histogram bars by specifying a color as
follows:

```{r}
ggplot(d, aes(x = FinalGradeCEMS)) +
  geom_histogram(fill = "blue")
```

### Changing colors

#### [**Your Turn**]{style="color: green;"} **â¤µ**

In the code chunk below, change the color to one of your choosing;
consider this list of valid color names here:
<http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf>

```{r}
ggplot(d, aes(x = FinalGradeCEMS)) +
  geom_histogram(fill = "blue")
```

Finally, we'll make one more change; visualize the distribution of
another variable in the data - one other than FinalGradeCEMS. You can do
so by swapping out the name for another variable with FinalGradeCEMS.
Also, change the color to one other than blue.

```{r}
ggplot(d, aes(x = FinalGradeCEMS)) +
  geom_histogram(fill = "blue")
```

### Reach 2 ðŸŽ‰

Completed the above? Nice job! Try for a "reach" by creating a scatter
plot for the relationship between two variables. You will need to pass
the names of two variables to the code below for what is now simply XXX
(a placeholder).

```{r, eval=FALSE}
ggplot(d, aes(x = TimeSpent, y = total_points_earned)) +
  geom_point()
```

## 4. MODEL

"Model" is one of those terms that has many different meanings. For our
purpose, we refer to the process of simplifying and summarizing our
data. Thus, models can take many forms; calculating means represents a
legitimate form of modeling data, as does estimating more complex
models, including linear regressions, and models and algorithms
associated with machine learning tasks. For now, we'll run a linear
regression to predict students' final grades.

Below, we predict students' final grades (`FinaGradeCEMS`, which is on a
0-100 point scale) on the basis of the time they spent on the course
(measured through their learning management system in minutes,
`TimeSpent`, and the subject (one of five) of their specific course.

```{r}
m1 <- lm(FinalGradeCEMS ~ TimeSpent + subject, data = d)
summary(m1)
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

Notice how above the variables are separated by a + symbol. Below, add
*another* - a third - variable to the regression model. Specifically,
add a variable students' initial, self-reported interest in science,
`int` - and any other variable(s) you like! What do you notice about the
results? We're going to dive into this *much* more: if you have many
questions now, you're in the right spot!

```{r}
m2 <- lm(FinalGradeCEMS ~ TimeSpent + subject, data = d)
summary(m2)
```

## 5. COMMUNICATE

The final step in the workflow/process is sharing the results of your
analysis with wider audience. Krumm et al. (2018) have outlined the
following 3-step process for communicating with education stakeholders
findings from an analysis:

1.  **Select.**Â Communicating what one has learned involves selecting
    among those analyses that are most important and most useful to an
    intended audience, as well as selecting a form for displaying that
    information, such as a graph or table in static or interactive form,
    i.e.Â a "data product."

2.  **Polish**. After creating initial versions of data products,
    research teams often spend time refining or polishing them, by
    adding or editing titles, labels, and notations and by working with
    colors and shapes to highlight key points.

3.  **Narrate.**Â Writing a narrative to accompany the data products
    involves, at a minimum, pairing a data product with its related
    research question, describing how best to interpret the data
    product, and explaining the ways in which the data product helps
    answer the research question.

In later Learning Labs, you will have an opportunity to create a simple
"data product" designed to illustrate insights some insights gained from
your analysis and ideally highlight an "action step" that can be taken
to act upon your findings.

For now, we will wrap up this case study by converting our work into a
webpage that can be used to communicate your learning and demonstrate
some of your new R skills. To do so, you will need to "knit" your
document by clicking the knit button next to the yarn ball in the menu
bar at that the top of this file. This will do two things; it will:

1.  check through all your code for any errors; and,

2.  create a file in your directory that you can use to share you work
    throughÂ [RPubs](#0)Â (see screenshot example below to
    publish),Â [GitHub Pages](#0),Â [Quarto Pub](#0), or anyÂ [other
    methods](#0).

Congratulations, you've completed your first LASER Badge! Complete the
following steps to submit your work for review:

1.  Change the name of the `author:` in the [YAML
    header](https://monashdatafluency.github.io/r-rep-res/yaml-header.html)
    at the very top of this document to your name. As noted in
    [Reproducible Research in
    R](https://monashdatafluency.github.io/r-rep-res/index.html), The
    YAML header controls the style and feel for knitted document but
    doesn't actually display in the final output.

2.  Click the "knit" button with the yarn ball icon above to "knit" your
    data product to a
    [HTML](https://bookdown.org/yihui/rmarkdown/html-document.html) file
    that will be saved in your R Project folder.

3.  Publish on [RPubs](https://rpubs.com) by clicking the "Publish"
    button located in the Viewer Pane when you knit your document. Note,
    you will need to quickly create a RPubs account.

    -   Publishing on GitHub using either [GitHub
        Pages](https://pages.github.com) or the [HTML
        previewer](http://htmlpreview.github.io).

4.  Post a new discussion on GitHub to our [Foundations Badges
    forum](https://github.com/orgs/laser-institute/teams/foundations/discussions/2).
    In your post, include a link to your published web page and a short
    reflection highlighting one thing you learned from this lab and one
    thing you'd like to explore further.

### References
